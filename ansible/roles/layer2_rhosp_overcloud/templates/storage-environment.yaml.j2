## A Heat environment file which can be used to set up storage
## backends. Defaults to Ceph used as a backend for Cinder, Glance and
## Nova ephemeral storage.
parameter_defaults:

# see https://access.redhat.com/documentation/en/red-hat-openstack-platform/8/director-installation-and-usage/67-configuring-nfs-storage

  #### BACKEND SELECTION ####

  ## Whether to enable iscsi backend for Cinder.
  CinderEnableIscsiBackend: false
  ## Whether to enable rbd (Ceph) backend for Cinder.
  CinderEnableRbdBackend: false
  ## Whether to enable NFS backend for Cinder.
  CinderEnableNfsBackend: true
  ## Whether to enable rbd (Ceph) backend for Nova ephemeral storage.
  NovaEnableRbdBackend: false
  ## Glance backend can be either 'rbd' (Ceph), 'swift' or 'file'.
  GlanceBackend: file


  #### CINDER NFS SETTINGS ####

  ## NFS mount options
  # CinderNfsMountOptions: ''
  CinderNfsMountOptions: 'rw,sync'
  ## NFS mount point, e.g. '192.168.122.1:/export/cinder'
  CinderNfsServers: '{{ infrastructure_address_nfs_server }}:{{ nfs_rhosp_cinder_path }}'


  #### GLANCE FILE BACKEND PACEMAKER SETTINGS (used for mounting NFS) ####

  ## Whether to make Glance 'file' backend a mount managed by Pacemaker
  GlanceFilePcmkManage: true
  ## File system type of the mount
  GlanceFilePcmkFstype: nfs
  ## Pacemaker mount point, e.g. '192.168.122.1:/export/glance' for NFS
  GlanceFilePcmkDevice: '{{ infrastructure_address_nfs_server }}:{{ nfs_rhosp_glance_path }}'
  ## Options for the mount managed by Pacemaker
  # GlanceFilePcmkOptions: ''
  GlanceFilePcmkOptions: 'rw,sync,context=system_u:object_r:glance_var_lib_t:s0'

  #### CEPH SETTINGS ####

  ## Whether to deploy Ceph OSDs on the controller nodes. By default
  ## OSDs are deployed on dedicated ceph-storage nodes only.
  ControllerEnableCephStorage: false

  ## When deploying Ceph through the oscplugin CLI, the following
  ## parameters are set automatically by the CLI. When deploying via
  ## heat stack-create, they need to be provided manually.

  ## Number of Ceph storage nodes to deploy
  # CephStorageCount: 0
  ## Ceph FSID, e.g. '4b5c8c0a-ff60-454b-a1b4-9747aa737d19'
  # CephClusterFSID: ''
  ## Ceph monitor key, e.g. 'AQC+Ox1VmEr3BxAALZejqeHj50Nj6wJDvs96OQ=='
  # CephMonKey: ''
  ## Ceph admin key, e.g. 'AQDLOh1VgEp6FRAAFzT7Zw+Y9V6JJExQAsRnRQ=='
  # CephAdminKey: ''
